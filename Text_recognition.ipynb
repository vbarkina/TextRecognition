{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import string\n",
    "import sys\n",
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\faps2\\neyronochky\\text_recognotion\\Train.csv\",header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          0.png  f\n",
       "0        1.png  H\n",
       "1        2.png  n\n",
       "2        3.png  K\n",
       "3        4.png  o\n",
       "4        5.png  z\n",
       "5        6.png  X\n",
       "6        7.png  E\n",
       "7        8.png  w\n",
       "8        9.png  5\n",
       "9       10.png  s\n",
       "10      11.png  K\n",
       "11      12.png  r\n",
       "12      13.png  X\n",
       "13      14.png  t\n",
       "14      15.png  T\n",
       "15      16.png  N\n",
       "16      17.png  E\n",
       "17      18.png  4\n",
       "18      19.png  f\n",
       "19      20.png  o\n",
       "20      21.png  t\n",
       "21      22.png  d\n",
       "22      23.png  p\n",
       "23      24.png  1\n",
       "24      25.png  A\n",
       "25      26.png  e\n",
       "26      27.png  A\n",
       "27      28.png  F\n",
       "28      29.png  u\n",
       "29      30.png  N\n",
       "...        ... ..\n",
       "4969  4970.png  W\n",
       "4970  4971.png  F\n",
       "4971  4972.png  K\n",
       "4972  4973.png  j\n",
       "4973  4974.png  k\n",
       "4974  4975.png  4\n",
       "4975  4976.png  t\n",
       "4976  4977.png  t\n",
       "4977  4978.png  S\n",
       "4978  4979.png  m\n",
       "4979  4980.png  x\n",
       "4980  4981.png  k\n",
       "4981  4982.png  l\n",
       "4982  4983.png  n\n",
       "4983  4984.png  H\n",
       "4984  4985.png  6\n",
       "4985  4986.png  h\n",
       "4986  4987.png  D\n",
       "4987  4988.png  X\n",
       "4988  4989.png  7\n",
       "4989  4990.png  C\n",
       "4990  4991.png  j\n",
       "4991  4992.png  7\n",
       "4992  4993.png  0\n",
       "4993  4994.png  M\n",
       "4994  4995.png  P\n",
       "4995  4996.png  h\n",
       "4996  4997.png  E\n",
       "4997  4998.png  n\n",
       "4998  4999.png  M\n",
       "\n",
       "[4999 rows x 2 columns]>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MAX_CHAR = 64\n",
    "def LoadData(FP = '.'):\n",
    "    TFP = os.path.join(FP, 'Train.csv')\n",
    "    A, Y, T, FN = [], [], [], []\n",
    "    with open(TFP) as F:\n",
    "        for Li in F:\n",
    "            FNi, Yi = Li.strip().split(',')  #filename,string\n",
    "            if(Yi == ''):\n",
    "                Yi = \" \"\n",
    "            T.append(Yi) #the letter in the picture\n",
    "            A.append(imread(os.path.join(FP, '', FNi))) #updated array of symbols\n",
    "            Y.append(list(Yi))   #list of letters\n",
    "#             A.append(imread(os.path.join(FP, '', FNi)))\n",
    "#             Y.append(list(Yi) + [' '] * (MAX_CHAR - len(Yi)))  \n",
    "            FN.append(FNi) #connection between the table and pictures\n",
    "    return np.stack(A), np.stack(Y), np.stack(T), np.stack(FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A, Y, T, FN = LoadData(FP = r'C:\\Users\\faps2\\neyronochky\\text_recognotion') #current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['H'], dtype='<U1')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0, 213, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   0,   0, 204],\n",
       "       [204, 204, 251, ..., 255,  52,  52],\n",
       "       [ 52,   0,   0, ...,   0,   0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.reshape([-1,28*28]) #translate pictures to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 28, 28, 3)\n",
      "(5000, 2352)\n"
     ]
    }
   ],
   "source": [
    "print(A.shape)\n",
    "print(A.reshape([-1,28*28*3]).shape)  #translate pictures to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представляем текст в виде векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string          \n",
    "CS = list(string.ascii_letters) + list(string.digits) + list(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представление буквы числом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38, 39, 40, 41], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(CS)\n",
    "le.transform(CS[1:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразовываем Y в вектор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(np.expand_dims(le.transform(CS),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faps2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "Y=le.transform(Y)\n",
    "Y=enc.transform(np.expand_dims(Y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left = 0 #0\n",
    "middle = 4500 #4500\n",
    "right = 5000 #5000\n",
    "X_train=X[left:middle]\n",
    "X_test=X[middle:right]\n",
    "Y_train=Y[left:middle,:]\n",
    "Y_test=Y[middle:right,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faps2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "shape=X_train.shape\n",
    "X_train=X_train.reshape((shape[0],-1))\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_train=X_train.reshape(shape)\n",
    "shape=X_test.shape\n",
    "X_test=X_test.reshape((shape[0],-1))\n",
    "X_test=scaler.transform(X_test)\n",
    "X_test=X_test.reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 63)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()  \n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(63, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 4.1426 - acc: 0.0196\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 16s 4ms/step - loss: 4.0042 - acc: 0.0476\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 16s 3ms/step - loss: 3.3959 - acc: 0.1467\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 2.6687 - acc: 0.2711\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 16s 4ms/step - loss: 1.9927 - acc: 0.4131\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 15s 3ms/step - loss: 1.5562 - acc: 0.5273\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 15s 3ms/step - loss: 1.1650 - acc: 0.6302\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 15s 3ms/step - loss: 0.9061 - acc: 0.7064\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 15s 3ms/step - loss: 0.7427 - acc: 0.7589\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 16s 4ms/step - loss: 0.6147 - acc: 0.7964\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 15s 3ms/step - loss: 0.5334 - acc: 0.8262\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 15s 3ms/step - loss: 0.4461 - acc: 0.8511\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 15s 3ms/step - loss: 0.3894 - acc: 0.8729\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 15s 3ms/step - loss: 0.3727 - acc: 0.8802\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 16s 4ms/step - loss: 0.3213 - acc: 0.8896\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 16s 4ms/step - loss: 0.2911 - acc: 0.8991\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 16s 4ms/step - loss: 0.2552 - acc: 0.9136\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 15s 3ms/step - loss: 0.2377 - acc: 0.9196\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 15s 3ms/step - loss: 0.2383 - acc: 0.9187\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 16s 4ms/step - loss: 0.2069 - acc: 0.9256\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 16s 4ms/step - loss: 0.2164 - acc: 0.9282\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 15s 3ms/step - loss: 0.1966 - acc: 0.9338\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 16s 3ms/step - loss: 0.1963 - acc: 0.9347\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 16s 4ms/step - loss: 0.1736 - acc: 0.9402\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 15s 3ms/step - loss: 0.1612 - acc: 0.9449\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 15s 3ms/step - loss: 0.1550 - acc: 0.9473\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 16s 4ms/step - loss: 0.1363 - acc: 0.9556\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 16s 3ms/step - loss: 0.1419 - acc: 0.9524\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 16s 4ms/step - loss: 0.1338 - acc: 0.9536\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 17s 4ms/step - loss: 0.1405 - acc: 0.9547\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 15s 3ms/step - loss: 0.1194 - acc: 0.9593\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 15s 3ms/step - loss: 0.1162 - acc: 0.9620\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 15s 3ms/step - loss: 0.1252 - acc: 0.9589\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 16s 3ms/step - loss: 0.1033 - acc: 0.9660\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.1014 - acc: 0.9660\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 17s 4ms/step - loss: 0.0952 - acc: 0.9678\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 17s 4ms/step - loss: 0.1133 - acc: 0.9627\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 16s 4ms/step - loss: 0.0901 - acc: 0.9693\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 16s 4ms/step - loss: 0.0946 - acc: 0.9669\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 17s 4ms/step - loss: 0.0920 - acc: 0.9680\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0834 - acc: 0.9689\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0773 - acc: 0.9744\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0808 - acc: 0.9707\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 17s 4ms/step - loss: 0.0825 - acc: 0.9700\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 16s 4ms/step - loss: 0.0659 - acc: 0.9773\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0874 - acc: 0.9687\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 17s 4ms/step - loss: 0.0701 - acc: 0.9758\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0929 - acc: 0.9671\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 17s 4ms/step - loss: 0.0888 - acc: 0.9678\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 17s 4ms/step - loss: 0.0687 - acc: 0.9782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c8474b35c0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=40, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAAgCAIAAAANLF6zAAAE4klEQVR4nO3c30tTfxzH8bP64o/a\npqLShuhi2RIhhRg2ddAkSVg0ugjUrrzuQq+6KLwIirpof0AXBipBCZGcnCRFKBGmUy+iXxMUUS8y\nSWexzQ1zny78fofYFz375bHxfFztfeC983pzDnw422eTJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAABJcrvdMzMzqpx6aWlJCCGEGBkZ2c9epEqqroLD4RBCVFRUpCgXgIx1SO0AGcJgMGg0mr6+\nvn3uRapwFQDsMxZgAABUkGkL8MbGRlNT08ePH0Oh0OTkpM1mU97b1NT05s2bHz9+rKysdHd3FxYW\npi9nqly8eHFiYiIcDvv9/qdPn5aVlambZ2RkpKenZ8fBrKysX79+Xb16Vck7JDxRdnb2xsZGS0uL\n3W6fmpqKRCKBQODUqVPxDZCQzs7Ob9++hUKhoaGh0tLSfTgjgAyQaQtwQUFBR0eHy+UymUx+v//x\n48eHDimasba2dnBw0Ov1Hj9+3G63V1dXy7Ks0WjSHTgZDofj+fPnsiwbDAar1Wo0Gl++fJmVlaVi\nJJ/Pd+LEiR0HzWbz4cOHP3/+vGd7MhNFIpGZmZnz5893dXVdv35dq9WWlpbOzc0lMkY8mpubb9++\nfePGjWPHjrnd7lu3bqX7jABw4LjdbiGEyWTaKl0u1/Zyd8+ePXv//n2srK+vF0LU19fHFeDJkycJ\nb+FJoNfj8YyPj8fKqqoqIcTly5cTC5ASHR0dX79+3XHQ5XJtbm7m5OTs2Z7kRK9fv97c3HQ4HErj\n/iGBqzAwMOD1emPlvXv32IQFQIlMewJeWlqan5/fer28vCxJUlFRkZJGq9X69u3bWDk6Orq+vn76\n9Ol0hEyVmpqad+/excoPHz6Ew+EzZ86oGMnn8xkMhqNHj5aUlESjUY/HI0nSyZMn5+bmwuHwnu1J\nTrS+vj4/P7/Pm8krKysnJiZi5fb8ALCLTFuAg8HgjiMKP0bW6/XXrl0T/4lGo7m5uSUlJWnImDJ6\nvf7nz5+xUggRCAR0Op2Kkb58+SJJktlsdrlc/f39drs9NzfXYrF8+vRJSXvyE83OzsabOUlarXb7\nXffnHQgA/+sftQMcFKurq729ve3t7WoHicPa2pper4+VGo1Gq9Wura2pl0haXFwMBoNms/nSpUsP\nHz7U6XQNDQ3l5eXbP6TdRfITRSKReDMnKRQK5eXlxcr8/Px9DgDgL5VpT8AJGx0draurUztFfMbG\nxmpra2NldXV1Tk7O2NiYipGEENPT0xaL5ezZsy9evJBl2el0mkwmJTuwpAM50Z6mp6e3f1Vx7tw5\nFcMA+IuwAP/L7XZXVVXduXOnqKiosLCwvb19YWHBaDSqnWs39+/ft1qtN2/e1Ov1FovlwYMHk5OT\nr169UjeVz+e7cuXK8PBwKBSSZbmhocFoNCpcgA/mRLvr6+uz2WxtbW06nc7pdCazBQwA/lY7/orS\nZrMJIaxWq8J2h8OxtffK7/cPDw83NjYqbAwEAuIPQ0ND6e6VJMnpdG795nVlZeXRo0fFxcUKG9On\ns7MzGo22trZulV6vNxqNHjlyRGF7MhN5PJ6tbV/xSuYqaDSau3fvfv/+PRgMyrJ84cIFIURlZWUC\nMQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAASLvf7yl2Zpa6DlkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=640x32 at 0x1C84A14B898>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "img=Image.open(r'C:\\Users\\faps2\\neyronochky\\text_recognotion\\hello.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 640, 3)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.asarray(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "picture = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faps2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ']\n",
      "[' ']\n",
      "[' ']\n",
      "[' ']\n",
      "['h']\n",
      "['e']\n",
      "['l']\n",
      "['l']\n",
      "['o']\n",
      "[' ']\n",
      "[' ']\n",
      "['w']\n",
      "['o']\n",
      "['r']\n",
      "['l']\n",
      "['d']\n",
      "[' ']\n",
      "[' ']\n",
      "[' ']\n",
      "[' ']\n",
      "[' ']\n",
      "[' ']\n",
      "[' ']\n",
      "[' ']\n",
      "[' ']\n",
      "[' ']\n",
      "[' ']\n",
      "[' ']\n",
      "[' ']\n",
      "[' ']\n",
      "[' ']\n",
      "[' ']\n",
      "[' ']\n",
      "[' ']\n",
      "[' ']\n",
      "[' ']\n",
      "[' ']\n",
      "[' ']\n",
      "[' ']\n",
      "[' ']\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "size = 28\n",
    "np.seterr(all='ignore', invalid = 'ignore')\n",
    "y=0\n",
    "while(True):\n",
    "    if y>img.shape[0]-size:\n",
    "        break\n",
    "    x=0\n",
    "    while(True):\n",
    "        if x>img.shape[1]-size:\n",
    "            break\n",
    "        X=picture[y:y+size, x:x+size, :] \n",
    "        X=np.expand_dims(X,0)\n",
    "        shape=X.shape\n",
    "        X=X.reshape((shape[0],-1))\n",
    "        X=scaler.transform(X)\n",
    "        X=X.reshape(shape)\n",
    "        #print(X.shape)\n",
    "        pred=model.predict([X])\n",
    "        answer=np.argmax(pred)\n",
    "        #print(le.inverse_transform([answer]))\n",
    "        if pred.size>0 and pred[0][answer]>0.90:\n",
    "            #print(answer)\n",
    "            print(le.inverse_transform([answer]))\n",
    "        x=x+int(size/2)\n",
    "    y=y+int(size/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность предсказания:  97.2 %\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "size=len(X_test)\n",
    "for i in range(size):\n",
    "    if np.argmax(Y_test[i])==np.argmax(model.predict(np.expand_dims(X_test[i],0))[0]):\n",
    "        count=count+1\n",
    "    \n",
    "print('Точность предсказания: ',(100*count/size),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
